{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!source /etc/profile\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import time\n",
        "from collections import deque\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization, Activation, Flatten, MaxPooling2D, Conv2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import utils\n",
        "import keras_tuner as kt\n",
        "import joblib\n",
        "\n",
        "# CD to top level git directory\n",
        "if \".git\" not in os.listdir(\".\"):\n",
        "    os.chdir(\"../../\")\n",
        "\n",
        "# Check GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "# tf.config.list_physical_devices()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:05:27.373399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:27.455809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:27.456491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
          ]
        }
      ],
      "metadata": {
        "id": "ffhd5Sy__sCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import gzip\n",
        "compressed_bstr = b\"\\x1f\\x8b\\x08\\x00\\xdf\\xd7\\x7e\\x62\\x02\\xff\\xa5\\x55\\x4b\\x8f\\xdb\\x20\\x10\\x3e\\x67\\x7f\\x05\\xe5\\x04\\x92\\x13\\xed\\xa3\\x2f\\x45\\xbb\\xab\\x5e\\xaa\\xaa\\x97\\x6a\\x2f\\x3d\\x59\\x16\\x22\\x06\\xa7\\x53\\x61\\xec\\x00\\xde\\xcd\\xb6\\xea\\x7f\\xef\\x80\\x13\\x39\\x91\\x9d\\x55\\xba\\xbd\\xd8\\x30\\x7c\\xf3\\xcd\\x83\\x99\\x01\\xea\\xb6\\x71\\x81\\xf8\\x6e\\xd5\\xba\\xa6\\xd4\\xde\\x13\\xe9\\x89\\x6f\\x2f\\x4a\\x23\\x71\\xfd\\xe5\\xe1\\xfb\\xf2\\x62\\xa6\\x74\\x45\\x84\\x00\\x0b\\x41\\x08\\xe6\\xb5\\xa9\\x38\\x0a\\x67\\x71\\xb1\\x10\\x42\\xc9\\x20\\x85\\x20\\x77\\xe4\\x5b\\x63\\xf5\\x1e\\xbb\\xd6\\xa1\\x97\\x0f\\x70\\xa7\\x43\\xe7\\x2c\\x52\\x2f\\x5c\\x67\\x19\\xa3\\xf6\\x11\\x14\\xc8\\xb9\\xaf\\x81\\x66\\x84\\xce\\x37\\xe9\\xbb\\xa5\\x3c\\x23\\x3e\\xa8\\xa6\\x0b\\x77\\x88\\x7c\\xf8\\xfa\\xf0\\x99\\x2f\\xfa\\xfd\\x42\\xe9\\xb2\\x51\\x9a\\xd1\\x2e\\x54\\xf3\\x8f\\x14\\xc5\\xad\\x81\\x60\\xc0\\x6a\\xcf\\xf8\\xe0\\x63\\x14\\x08\\x0c\\xa5\\xd5\\x2e\\x3c\\xef\\xec\\x67\\x44\\x85\\xe7\\x56\\x67\\xa4\\xb5\\xb2\\xd6\\xc9\\x1b\\xa8\\xc8\\x91\\xff\\x51\\x36\\x8b\\x4b\\x0c\\xe4\\xe8\\x00\\xe5\\xda\\x78\\x3d\\x71\\x3e\\xc4\\xc8\\x87\\xf0\\x72\\x96\\x4c\\x31\\xe8\\xdd\\x63\\xf4\\x9e\\xf2\\xfc\\xaa\\xd8\\xef\\x6e\\x71\\x77\\xb9\\xdf\\xc5\\x25\\xcf\\xce\\x43\\xce\\xaf\\x0a\\x4e\\xaa\\xc6\\x11\\x20\\x60\\x49\\x72\\x04\\x43\\x48\\xf1\\x44\\x01\\x14\\x08\\xbe\\x98\\x7d\\xda\\x07\\xde\\xe7\\x23\\x9e\\x8e\\x2e\\x20\\x7f\\xd1\\xe0\\x60\\x63\\x1c\\x65\\xb4\\x48\\x6f\\xd1\\x84\\xea\\xca\\x20\\x22\\xf9\\x3d\\x3d\\x6d\\xbc\\xd6\\xf5\\x60\\xfb\\xa5\\xcc\\x85\\x26\\x48\\x93\\x91\\xce\\x6b\\x95\\x91\\xca\\x69\\x8d\\xc0\\x9c\\x81\\x0d\\x2c\\x82\\x72\\x28\\xce\\x4e\\xe5\\xbf\\xe0\\x8f\\xf2\\xe9\\xa4\\x5d\\x6b\\x66\\xb4\\x4d\\x26\\xf9\\x2e\\xd2\\x6a\\x25\\x30\\x88\\xc6\\x3d\\x8b\\xce\\xcb\\xf5\\x2e\\xd8\\xde\\x06\\x5e\\x07\\x41\\xe5\\x97\\x31\\xd7\\x67\\x60\\x6e\\x8a\\xa2\\xbf\\x1a\\x0c\\x3a\\x15\\x0e\\xc5\\x3e\\x60\\xcd\\xea\\xa7\\x2e\\x43\\x86\\xbd\\xf0\\x9b\\xa6\\x74\\x41\\xd0\\xb5\\x10\\x74\\x49\\x8c\\xac\\x57\\x4a\\x12\\x9f\\xc1\\x12\\x93\\x34\\x4a\\x1d\\xcf\\x73\\x9a\\x84\\xb1\\x9b\\xa2\\x38\\xfe\\xe3\\x01\\x2d\\x16\\x60\\x95\\xde\\xb2\\x0d\\x2f\\x62\\x74\\xe0\\xc1\\xfa\\x20\\x6d\\xa9\\xd9\\x26\\x76\\x9c\\xe3\\x24\\x96\\x39\\x99\\xa2\\xdc\\xf4\\x55\\xb1\\x89\\x6e\\x63\\x7a\\xe3\\x6d\\x23\\xab\\x10\\x4e\\xb7\\xee\\xc8\\xa9\\xe5\\x94\\xfa\\x62\\x0f\\x64\\xfc\\x0f\\x3f\\x6c\\x15\\xfc\\x8d\\x8a\\x26\\x25\\x68\\x3c\\x33\\xfa\\xb2\\x19\\x37\\x37\\x16\\x09\\x7a\\x72\\xbb\\x6e\\x3b\\xd1\\x05\\x30\\x78\\xe1\\x23\\x46\\x4c\\x5c\\xfb\\x2a\\xc2\\xa8\\x38\\x45\\xd8\\x36\\x4f\\xda\\x9d\\xcf\\x58\\x99\\x46\\x26\\xce\\xa4\\x27\\x94\\x93\\x4f\\x53\\xac\\xb5\\xdc\\xfe\\x1f\\xb1\\x81\\x1a\\xc2\\x14\\x73\\xd9\\x29\\x29\\x1e\\xb5\\xf3\\xd0\\xd8\\xf3\\xd9\\xb1\\x22\\x22\\xf7\\xa1\\xf2\\x7d\\x6a\\xa0\\x11\\xbf\\x72\\x80\\x80\\x57\\x5b\\x38\\x56\\x3f\\x61\\x43\\x1a\\x73\\xfa\\xdd\\x99\\x1c\\x2a\\x32\\x04\\xe7\\xe3\\x20\\xd9\\xa6\\xda\\xdd\\xa6\\x96\\x83\\x5d\\x7a\\x63\\x03\\xd8\\x26\\x90\\x2d\\x3e\\x2d\\xd2\\x05\\xff\\x04\\xe1\\x07\\xc3\\x82\\xa6\\x9c\\x48\\xab\\x10\\xfc\\xe6\\x8e\\x50\\xb4\\x49\\x8b\\x43\\xa6\\xb4\\xc8\\xe3\\x5c\\x02\\x7e\\x30\\x27\\xe9\\xdb\\x9b\\x0f\\xef\\xdf\\x5d\\x5f\\x5e\\xd1\\xa1\\x93\\x15\\x94\\x81\\xfd\\x82\\x96\\x25\\x9d\\x8c\\xe4\\x83\\x8f\\x51\\x02\\xab\\x2e\\x68\\x74\\x54\\xf6\\x23\\x48\\x46\\x9a\\x84\\x2c\\x38\\x3f\\xf9\\xb0\\x1e\\xb6\\x0d\\xd6\\x27\\xca\\xf1\\x71\\x66\\xfc\\x2f\\x17\\xd9\\x71\\x54\\xc0\\x07\\x00\\x00\"\n",
        "exec(gzip.decompress(compressed_bstr))\n",
        "\n",
        "gpu.name"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fjnW-h2Fhstg",
        "outputId": "e65d9403-a049-4bb5-99a6-a1578456f33f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# Data parameters\n",
        "SEQ_LEN = 336 #hours\n",
        "FUTURE_PERIOD_PREDICT = 1 #hours\n",
        "\n",
        "# Hyperparameter Optimizer parameters\n",
        "MAX_TRIALS = 100 # 10t x 20e ~ 4h\n",
        "\n",
        "# Model parameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "NAME = \"TRANSFORMER-01\""
      ],
      "outputs": [],
      "metadata": {
        "id": "C4kS-9a0AMqP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "## Import Data\n",
        "\n",
        "train_df = pd.read_csv(\"data/formatted/BTCUSDT-1h-data.csv\")\n",
        "train_df.set_index(\"timestamp\", inplace=True)\n",
        "train_df"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>rsi</th>\n",
              "      <th>ema</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1503064800</th>\n",
              "      <td>4304.15</td>\n",
              "      <td>4371.52</td>\n",
              "      <td>4296.04</td>\n",
              "      <td>4356.31</td>\n",
              "      <td>51.563675</td>\n",
              "      <td>52.623958</td>\n",
              "      <td>4327.151560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503068400</th>\n",
              "      <td>4356.31</td>\n",
              "      <td>4357.37</td>\n",
              "      <td>4302.72</td>\n",
              "      <td>4340.31</td>\n",
              "      <td>24.093449</td>\n",
              "      <td>51.678528</td>\n",
              "      <td>4327.804777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503072000</th>\n",
              "      <td>4320.52</td>\n",
              "      <td>4340.31</td>\n",
              "      <td>4287.79</td>\n",
              "      <td>4331.71</td>\n",
              "      <td>15.118957</td>\n",
              "      <td>51.167386</td>\n",
              "      <td>4327.995329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503075600</th>\n",
              "      <td>4302.97</td>\n",
              "      <td>4318.16</td>\n",
              "      <td>4221.05</td>\n",
              "      <td>4293.09</td>\n",
              "      <td>46.533767</td>\n",
              "      <td>48.919621</td>\n",
              "      <td>4326.319858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503079200</th>\n",
              "      <td>4293.09</td>\n",
              "      <td>4293.09</td>\n",
              "      <td>4193.70</td>\n",
              "      <td>4259.40</td>\n",
              "      <td>74.368943</td>\n",
              "      <td>47.054235</td>\n",
              "      <td>4323.157459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642464000</th>\n",
              "      <td>42174.66</td>\n",
              "      <td>42318.61</td>\n",
              "      <td>42095.69</td>\n",
              "      <td>42238.31</td>\n",
              "      <td>858.935040</td>\n",
              "      <td>40.857704</td>\n",
              "      <td>42832.082979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642467600</th>\n",
              "      <td>42238.31</td>\n",
              "      <td>42306.96</td>\n",
              "      <td>42013.12</td>\n",
              "      <td>42083.47</td>\n",
              "      <td>698.707920</td>\n",
              "      <td>38.983032</td>\n",
              "      <td>42807.934173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642471200</th>\n",
              "      <td>42078.64</td>\n",
              "      <td>42148.21</td>\n",
              "      <td>41609.78</td>\n",
              "      <td>41724.20</td>\n",
              "      <td>1463.109620</td>\n",
              "      <td>35.115683</td>\n",
              "      <td>42772.975006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642474800</th>\n",
              "      <td>41724.19</td>\n",
              "      <td>42392.66</td>\n",
              "      <td>41540.42</td>\n",
              "      <td>42077.19</td>\n",
              "      <td>1535.654060</td>\n",
              "      <td>41.058890</td>\n",
              "      <td>42750.530329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1642478400</th>\n",
              "      <td>42077.18</td>\n",
              "      <td>42296.14</td>\n",
              "      <td>42049.38</td>\n",
              "      <td>42181.12</td>\n",
              "      <td>527.879260</td>\n",
              "      <td>42.658635</td>\n",
              "      <td>42732.162254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38628 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                open      high       low     close       volume        rsi  \\\n",
              "timestamp                                                                    \n",
              "1503064800   4304.15   4371.52   4296.04   4356.31    51.563675  52.623958   \n",
              "1503068400   4356.31   4357.37   4302.72   4340.31    24.093449  51.678528   \n",
              "1503072000   4320.52   4340.31   4287.79   4331.71    15.118957  51.167386   \n",
              "1503075600   4302.97   4318.16   4221.05   4293.09    46.533767  48.919621   \n",
              "1503079200   4293.09   4293.09   4193.70   4259.40    74.368943  47.054235   \n",
              "...              ...       ...       ...       ...          ...        ...   \n",
              "1642464000  42174.66  42318.61  42095.69  42238.31   858.935040  40.857704   \n",
              "1642467600  42238.31  42306.96  42013.12  42083.47   698.707920  38.983032   \n",
              "1642471200  42078.64  42148.21  41609.78  41724.20  1463.109620  35.115683   \n",
              "1642474800  41724.19  42392.66  41540.42  42077.19  1535.654060  41.058890   \n",
              "1642478400  42077.18  42296.14  42049.38  42181.12   527.879260  42.658635   \n",
              "\n",
              "                     ema  \n",
              "timestamp                 \n",
              "1503064800   4327.151560  \n",
              "1503068400   4327.804777  \n",
              "1503072000   4327.995329  \n",
              "1503075600   4326.319858  \n",
              "1503079200   4323.157459  \n",
              "...                  ...  \n",
              "1642464000  42832.082979  \n",
              "1642467600  42807.934173  \n",
              "1642471200  42772.975006  \n",
              "1642474800  42750.530329  \n",
              "1642478400  42732.162254  \n",
              "\n",
              "[38628 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "g7lILMvU_yit",
        "outputId": "d360da33-d9be-499c-8d45-7da391274061"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "## Add min max bounds to data\n",
        "\n",
        "price_max = 80000.0\n",
        "volume_max = 60000.0\n",
        "rsi_max = 100.0\n",
        "\n",
        "price_min = 2000.0\n",
        "volume_min = 0.0\n",
        "rsi_min = 0.0\n",
        "\n",
        "max_df = pd.DataFrame()\n",
        "\n",
        "max_df[\"timestamp\"] = []\n",
        "\n",
        "for col in train_df.columns:\n",
        "    max_df[col] = []\n",
        "\n",
        "max_df = max_df.append({\"timestamp\": str(int(time.time())),\n",
        "                \"open\": price_max,\n",
        "                \"high\": price_max,\n",
        "                \"low\": price_max,\n",
        "                \"close\": price_max,\n",
        "                \"volume\": volume_max,\n",
        "                \"rsi\": rsi_max,\n",
        "                \"ema\": price_max,\n",
        "                \"target\": price_max}, ignore_index=True)\n",
        "\n",
        "max_df = max_df.append({\"timestamp\": str(int(time.time())),\n",
        "                \"open\": price_min,\n",
        "                \"high\": price_min,\n",
        "                \"low\": price_min,\n",
        "                \"close\": price_min,\n",
        "                \"volume\": volume_min,\n",
        "                \"rsi\": rsi_min,\n",
        "                \"ema\": price_min,\n",
        "                \"target\": price_min}, ignore_index=True)\n",
        "\n",
        "max_df.set_index(\"timestamp\", inplace=True)\n",
        "\n",
        "max_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>rsi</th>\n",
              "      <th>ema</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1654484729</th>\n",
              "      <td>80000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>80000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654484729</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               open     high      low    close   volume    rsi      ema  \\\n",
              "timestamp                                                                 \n",
              "1654484729  80000.0  80000.0  80000.0  80000.0  60000.0  100.0  80000.0   \n",
              "1654484729   2000.0   2000.0   2000.0   2000.0      0.0    0.0   2000.0   \n",
              "\n",
              "             target  \n",
              "timestamp            \n",
              "1654484729  80000.0  \n",
              "1654484729   2000.0  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "g7w3TqUJASjA",
        "outputId": "43284297-1562-4956-eb27-a0ea7dd16c16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "## Formatting data and Scaler Initialization\n",
        "\n",
        "# def classify(current, future):\n",
        "#     return float((future - current) / current)\n",
        "\n",
        "\n",
        "train_df[\"target\"] = train_df[\"close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
        "\n",
        "# # Cut off NaNs\n",
        "# # data = data[:-FUTURE_PERIOD_PREDICT]\n",
        "train_df.dropna(inplace=True)\n",
        "\n",
        "# data[\"target\"] = list(map(classify, data[\"close\"], data[\"future\"]))\n",
        "# # data[[\"close\", \"future\", \"target\"]].tail()\n",
        "# data = data.drop(\"future\", 1)\n",
        "\n",
        "# Fit scalers\n",
        "price_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
        "volume_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
        "rsi_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "train_df = train_df.append(max_df)\n",
        "\n",
        "price_scaler.fit(np.array(train_df[\"close\"]).reshape(-1, 1))\n",
        "volume_scaler.fit(np.array(train_df[\"volume\"]).reshape(-1, 1))\n",
        "rsi_scaler.fit(np.array(train_df[\"rsi\"]).reshape(-1, 1))\n",
        "\n",
        "#Dump scalers\n",
        "\n",
        "try:\n",
        "    os.mkdir(f\"scalers/{NAME}\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "joblib.dump(price_scaler, f\"scalers/{NAME}/price_scaler\")\n",
        "joblib.dump(volume_scaler, f\"scalers/{NAME}/volume_scaler\")\n",
        "joblib.dump(rsi_scaler, f\"scalers/{NAME}/rsi_scaler\")\n",
        "\n",
        "# Remove min max boundary values\n",
        "train_df = train_df[:-2]\n",
        "\n",
        "\n",
        "# Split dataset # Dont split here; do split after shuffle\n",
        "# last_5_pct = int(len(data) * .95)\n",
        "\n",
        "# train_data = data[:last_5_pct]\n",
        "# validation_data = data[last_5_pct:]\n",
        "\n",
        "# print(f\"{len(train_data)} :: {len(validation_data)}\")\n",
        "\n",
        "train_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>rsi</th>\n",
              "      <th>ema</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1503064800</th>\n",
              "      <td>4304.15</td>\n",
              "      <td>4371.52</td>\n",
              "      <td>4296.04</td>\n",
              "      <td>4356.31</td>\n",
              "      <td>51.563675</td>\n",
              "      <td>52.623958</td>\n",
              "      <td>4327.151560</td>\n",
              "      <td>4340.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503068400</th>\n",
              "      <td>4356.31</td>\n",
              "      <td>4357.37</td>\n",
              "      <td>4302.72</td>\n",
              "      <td>4340.31</td>\n",
              "      <td>24.093449</td>\n",
              "      <td>51.678528</td>\n",
              "      <td>4327.804777</td>\n",
              "      <td>4331.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503072000</th>\n",
              "      <td>4320.52</td>\n",
              "      <td>4340.31</td>\n",
              "      <td>4287.79</td>\n",
              "      <td>4331.71</td>\n",
              "      <td>15.118957</td>\n",
              "      <td>51.167386</td>\n",
              "      <td>4327.995329</td>\n",
              "      <td>4293.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503075600</th>\n",
              "      <td>4302.97</td>\n",
              "      <td>4318.16</td>\n",
              "      <td>4221.05</td>\n",
              "      <td>4293.09</td>\n",
              "      <td>46.533767</td>\n",
              "      <td>48.919621</td>\n",
              "      <td>4326.319858</td>\n",
              "      <td>4259.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503079200</th>\n",
              "      <td>4293.09</td>\n",
              "      <td>4293.09</td>\n",
              "      <td>4193.70</td>\n",
              "      <td>4259.40</td>\n",
              "      <td>74.368943</td>\n",
              "      <td>47.054235</td>\n",
              "      <td>4323.157459</td>\n",
              "      <td>4236.89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               open     high      low    close     volume        rsi  \\\n",
              "timestamp                                                              \n",
              "1503064800  4304.15  4371.52  4296.04  4356.31  51.563675  52.623958   \n",
              "1503068400  4356.31  4357.37  4302.72  4340.31  24.093449  51.678528   \n",
              "1503072000  4320.52  4340.31  4287.79  4331.71  15.118957  51.167386   \n",
              "1503075600  4302.97  4318.16  4221.05  4293.09  46.533767  48.919621   \n",
              "1503079200  4293.09  4293.09  4193.70  4259.40  74.368943  47.054235   \n",
              "\n",
              "                    ema   target  \n",
              "timestamp                         \n",
              "1503064800  4327.151560  4340.31  \n",
              "1503068400  4327.804777  4331.71  \n",
              "1503072000  4327.995329  4293.09  \n",
              "1503075600  4326.319858  4259.40  \n",
              "1503079200  4323.157459  4236.89  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "C1eOjSw6AZPE",
        "outputId": "6c6af02c-d9e3-441d-9dda-6b710ddaddc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "## Preprocess Data\n",
        "\n",
        "def preprocess_df_p1(df_p):\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    for col in df_p.columns:\n",
        "        df[col] = df_p[col]\n",
        "\n",
        "    for col in df.columns:\n",
        "        scaler = None\n",
        "        if col in [\"open\", \"high\", \"low\", \"close\", \"ema\", \"target\"]:\n",
        "            scaler = price_scaler\n",
        "        elif col == \"volume\":\n",
        "            scaler = volume_scaler\n",
        "        elif col == \"rsi\":\n",
        "            scaler = rsi_scaler\n",
        "        else:\n",
        "            raise Exception(\"Column not recognized and scaler cannot be determined\")\n",
        "\n",
        "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "        df.dropna(inplace=True)\n",
        "        df[col] = scaler.transform(np.array(df[col]).reshape(-1, 1))\n",
        "\n",
        "        \n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    sequential_data = []\n",
        "    prev_periods = deque(maxlen=SEQ_LEN)\n",
        "\n",
        "    for i in df.values:\n",
        "        prev_periods.append([n for n in i[:-1]])\n",
        "        if len(prev_periods) == SEQ_LEN:\n",
        "            sequential_data.append([np.array(prev_periods), i[-1]])\n",
        "\n",
        "    return sequential_data\n",
        "    # random.shuffle(sequential_data)\n",
        "\n",
        "def preprocess_df_p2(seq_data):\n",
        "\n",
        "    # Balance buys and sells\n",
        "    buys = []\n",
        "    sells = []\n",
        "\n",
        "    for seq, target in seq_data:\n",
        "\n",
        "        if target < seq[-1][3]: #compares to close column\n",
        "            sells.append([seq, target])\n",
        "        elif target > seq[-1][3]:\n",
        "            buys.append([seq, target])\n",
        "\n",
        "    lower = min(len(buys), len(sells))\n",
        "\n",
        "    buys = buys[:lower]\n",
        "    sells = sells[:lower]\n",
        "\n",
        "    local_seq_data = buys + sells\n",
        "\n",
        "    random.shuffle(local_seq_data)\n",
        "\n",
        "    X = [d[0] for d in local_seq_data]\n",
        "    Y = [d[1] for d in local_seq_data]\n",
        "\n",
        "    return np.array(X), np.array(Y)\n",
        "    \n",
        "\n",
        "# train_x, train_y = preprocess_df(train_data)\n",
        "# validation_x, validation_y = preprocess_df(validation_data)\n",
        "\n",
        "# Preprocess and split data here\n",
        "seq_data_full = preprocess_df_p1(train_df)\n",
        "\n",
        "last_5_pct = int(len(seq_data_full) * .95)\n",
        "\n",
        "seq_data_train = seq_data_full[:last_5_pct]\n",
        "seq_data_val = seq_data_full[last_5_pct:]\n",
        "\n",
        "train_x, train_y = preprocess_df_p2(seq_data_train)\n",
        "validation_x, validation_y = preprocess_df_p2(seq_data_val)"
      ],
      "outputs": [],
      "metadata": {
        "id": "91cQKgWBBUXc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "joblib.dump(train_x, \"data/pickle/train_x.dump\")\n",
        "joblib.dump(train_y, \"data/pickle/train_y.dump\")\n",
        "joblib.dump(validation_x, \"data/pickle/validation_x.dump\")\n",
        "joblib.dump(validation_y, \"data/pickle/validation_y.dump\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/pickle/validation_y.dump']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
        "where `sequence length` is the number of time steps and `features` is each input\n",
        "timeseries.\n",
        "\n",
        "You can replace your classification RNN layers with this one: the\n",
        "inputs are fully compatible!"
      ],
      "metadata": {
        "id": "UjreaeXOxVCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We include residual connections, layer normalization, and dropout.\n",
        "The resulting layer can be stacked multiple times.\n",
        "\n",
        "The projection layers are implemented through `keras.layers.Conv1D`."
      ],
      "metadata": {
        "id": "A9k_4EIYxVCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "8YANfU7pxVC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main part of our model is now complete. We can stack multiple of those\n",
        "`transformer_encoder` blocks and we can also proceed to add the final\n",
        "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
        "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
        "our model down to a vector of features for each data point in the current\n",
        "batch. A common way to achieve this is to use a pooling layer. For\n",
        "this example, a `GlobalAveragePooling1D` layer is sufficient."
      ],
      "metadata": {
        "id": "oXcyRcSixVC1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(1, activation=\"linear\")(x)\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "ESwuo-QhxVC3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def build_model_hp(hp):\n",
        "    kwargs = {\n",
        "        \"input_shape\": train_x.shape[1:],\n",
        "        \"head_size\": hp.Int(\"head_size\", min_value=32, max_value=1024, step=32),\n",
        "        \"num_heads\": hp.Int(\"num_heads\", min_value=2, max_value=10, step=1),\n",
        "        \"ff_dim\": 4,\n",
        "        \"num_transformer_blocks\": hp.Int(\"num_transformer_blocks\", min_value=2, max_value=10, step=1),\n",
        "        \"mlp_units\": [hp.Int(f\"mlp_units_{i}\", min_value=32, max_value=512, step=32) for i in range(hp.Int(\"mlp_count\", min_value=1, max_value=4, step=1))],\n",
        "        \"mlp_dropout\": hp.Float(\"mlp_dropout\", min_value=0.1, max_value=0.7, step=0.1),\n",
        "        \"dropout\": hp.Float(\"dropout\", min_value=0.1, max_value=0.5, step=0.1),\n",
        "    }\n",
        "\n",
        "    model = build_model(**kwargs)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"mape\",\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=hp.Choice(\"learning_rate\", values=[.001, .0001, .00001, .000001])),\n",
        "        metrics=[\"mse\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "RXcHrXa6PnMk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# input_shape = train_x.shape[1:]\n",
        "\n",
        "# model = build_model(\n",
        "#     input_shape,\n",
        "#     head_size=256,\n",
        "#     num_heads=4,\n",
        "#     ff_dim=4,\n",
        "#     num_transformer_blocks=4,\n",
        "#     mlp_units=[128],\n",
        "#     mlp_dropout=0.4,\n",
        "#     dropout=0.25,\n",
        "# )\n",
        "\n",
        "# model.compile(\n",
        "#     loss=\"mse\",\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "#     metrics=[\"mape\"],\n",
        "# )\n",
        "# model.summary()\n",
        "\n",
        "# callbacks = [keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "fADp2gbPxVC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Initialize Tuner\n",
        "\n",
        "tuner = kt.BayesianOptimization(\n",
        "                    max_trials=MAX_TRIALS,\n",
        "                    hypermodel=build_model_hp,\n",
        "                    objective=\"val_loss\",\n",
        "                    overwrite=False,\n",
        "                    directory=f\"tuners/{NAME}\",\n",
        "                    project_name=f\"{NAME}\",)\n",
        "\n",
        "tuner.search_space_summary(extended=True)\n",
        "\n",
        "callbacks = [\n",
        "                keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True),\n",
        "                keras.callbacks.TensorBoard(log_dir=f\"logs/{NAME}\",\n",
        "                                                 histogram_freq=1,\n",
        "                                                 profile_batch='500,520')\n",
        "\n",
        "            ]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:05:47.567912: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-06 03:05:47.569016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:47.570020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:47.570907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:49.662716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:49.663690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:49.664606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-06 03:05:49.665406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13791 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 8\n",
            "head_size (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': None}\n",
            "num_heads (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 10, 'step': 1, 'sampling': None}\n",
            "num_transformer_blocks (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 10, 'step': 1, 'sampling': None}\n",
            "mlp_count (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': None}\n",
            "mlp_units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "mlp_dropout (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.7, 'step': 0.1, 'sampling': None}\n",
            "dropout (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.001, 'conditions': [], 'values': [0.001, 0.0001, 1e-05, 1e-06], 'ordered': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:05:50.329916: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
            "2022-06-06 03:05:50.329950: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
            "2022-06-06 03:05:50.334179: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1630] Profiler found 1 GPUs\n",
            "2022-06-06 03:05:50.334755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib:\n",
            "2022-06-06 03:05:50.606242: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
            "2022-06-06 03:05:50.606379: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4IJPJjcSWP_",
        "outputId": "436d4916-7b7e-4add-eb9c-b1185cba3621"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "with tf.device(\"/device:GPU:0\"):\n",
        "    tuner.search(train_x, train_y, \n",
        "                epochs=EPOCHS,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=(validation_x, validation_y))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "head_size         |352               |?                 \n",
            "num_heads         |4                 |?                 \n",
            "num_transformer...|5                 |?                 \n",
            "mlp_count         |2                 |?                 \n",
            "mlp_units_0       |64                |?                 \n",
            "mlp_dropout       |0.6               |?                 \n",
            "dropout           |0.2               |?                 \n",
            "learning_rate     |0.001             |?                 \n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:06:48.873785: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
            "2022-06-06 03:06:50.704930: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
            "\n",
            "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6/2212 [..............................] - ETA: 4:17 - loss: 336.3530 - mse: 4.1300WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0576s vs `on_train_batch_end` time: 0.0823s). Check your callbacks.\n",
            " 499/2212 [=====>........................] - ETA: 2:51 - loss: 154.9052 - mse: 0.7478"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:07:41.753293: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
            "2022-06-06 03:07:41.753333: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 519/2212 [======>.......................] - ETA: 2:51 - loss: 152.9581 - mse: 0.7390"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:07:44.433954: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
            "2022-06-06 03:07:44.454882: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1764] CUPTI activity buffer flushed\n",
            "2022-06-06 03:07:44.732646: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:526]  GpuTracer has collected 23668 callback api events and 23605 activity events. \n",
            "2022-06-06 03:07:45.181678: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
            "2022-06-06 03:07:45.832927: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45\n",
            "\n",
            "2022-06-06 03:07:46.232664: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.trace.json.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 520/2212 [======>.......................] - ETA: 2:59 - loss: 152.8236 - mse: 0.7384"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-06 03:07:46.759971: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45\n",
            "\n",
            "2022-06-06 03:07:46.772392: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.memory_profile.json.gz\n",
            "2022-06-06 03:07:46.783549: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45\n",
            "Dumped tool data for xplane.pb to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.xplane.pb\n",
            "Dumped tool data for overview_page.pb to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to logs/TRANSFORMER-01/ebb627fea4f12d9329bcf086bd6c9046/execution0/plugins/profile/2022_06_06_03_07_45/ip-172-31-0-83.kernel_stats.pb\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2212/2212 [==============================] - 241s 104ms/step - loss: 113.1006 - mse: 0.5720 - val_loss: 140.4782 - val_mse: 0.1538\n",
            "Epoch 2/50\n",
            "1412/2212 [==================>...........] - ETA: 1:23 - loss: 98.3269 - mse: 0.5143"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2737/3815191364.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/device:GPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     tuner.search(train_x, train_y, \n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_batch_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs, is_batch_hook)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_batch_hook\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_hooks_support_tf_logs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByXROXBeSjNv",
        "outputId": "51c37a07-a8c6-451b-a8f2-a5cd9940c981"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of timeseries_transformer_classification",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('tf': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "03ca22c6d6d40835e149a115b42423f5eef12d1ffe1b81219c8386ff45d860ad"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}